{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af21084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bhoomish\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bhoomish\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bhoomish\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\bhoomish\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: click in c:\\users\\bhoomish\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhoomish\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b13936",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"In the heart of a bustling city, where skyscrapers reached for the clouds and streets buzzed with the constant hum of life, \\\n",
    "there existed a small, hidden café. Tucked away in a quiet alley, it was a sanctuary from the chaos, with its warm, \\\n",
    "inviting glow spilling out onto the cobblestones. The aroma of freshly brewed coffee mingled with the scent of old books that \\\n",
    "lined the shelves, creating an atmosphere of comfort and nostalgia. Patrons came not just for the beverages but for the solace and the \\\n",
    "quiet murmur of conversation that filled the air. Here, time seemed to slow, allowing moments to linger and dreams to take flight amidst the gentle clatter of cups and the soft rustle of pages turning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a097003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the heart of a bustling city, where skyscrapers reached for the clouds and streets buzzed with the constant hum of life, there existed a small, hidden café. Tucked away in a quiet alley, it was a sanctuary from the chaos, with its warm, inviting glow spilling out onto the cobblestones. The aroma of freshly brewed coffee mingled with the scent of old books that lined the shelves, creating an atmosphere of comfort and nostalgia. Patrons came not just for the beverages but for the solace and the quiet murmur of conversation that filled the air. Here, time seemed to slow, allowing moments to linger and dreams to take flight amidst the gentle clatter of cups and the soft rustle of pages turning.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35a852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd1ca18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BHOOMISH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")# we are downloading punkt package for tokenization to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48785350",
   "metadata": {},
   "source": [
    "# step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050a61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(paragraph)#we are tokenizing the paragraph in this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf3f7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the heart of a bustling city, where skyscrapers reached for the clouds and streets buzzed with the constant hum of life, there existed a small, hidden café.',\n",
       " 'Tucked away in a quiet alley, it was a sanctuary from the chaos, with its warm, inviting glow spilling out onto the cobblestones.',\n",
       " 'The aroma of freshly brewed coffee mingled with the scent of old books that lined the shelves, creating an atmosphere of comfort and nostalgia.',\n",
       " 'Patrons came not just for the beverages but for the solace and the quiet murmur of conversation that filled the air.',\n",
       " 'Here, time seemed to slow, allowing moments to linger and dreams to take flight amidst the gentle clatter of cups and the soft rustle of pages turning.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences#this has created the paragraph into a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5b03bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()#we are initializing the stemmer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717b673a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histor'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example for stemmer function\n",
    "stemmer.stem(\"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c07edd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BHOOMISH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24d58f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\BHOOMISH\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df6524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8728773e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'historical'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2d7c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re#we are importing regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5db4abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are removing all the special characters in the sentences\n",
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "  review=re.sub(\"[^a-zA-Z]\",\" \",sentences[i])#re.sub is a function which removes all the characters except alphabet including space so to exclude space we have mentioned a space in next comma\n",
    "  review=review.lower()\n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7529ea5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in the heart of a bustling city  where skyscrapers reached for the clouds and streets buzzed with the constant hum of life  there existed a small  hidden caf  ',\n",
       " 'tucked away in a quiet alley  it was a sanctuary from the chaos  with its warm  inviting glow spilling out onto the cobblestones ',\n",
       " 'the aroma of freshly brewed coffee mingled with the scent of old books that lined the shelves  creating an atmosphere of comfort and nostalgia ',\n",
       " 'patrons came not just for the beverages but for the solace and the quiet murmur of conversation that filled the air ',\n",
       " 'here  time seemed to slow  allowing moments to linger and dreams to take flight amidst the gentle clatter of cups and the soft rustle of pages turning ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25604fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BHOOMISH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7b20cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")#these are the list of all the stopwords in english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e4150f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart\n",
      "bustling\n",
      "city\n",
      "skyscraper\n",
      "reached\n",
      "cloud\n",
      "street\n",
      "buzzed\n",
      "constant\n",
      "hum\n",
      "life\n",
      "existed\n",
      "small\n",
      "hidden\n",
      "caf\n",
      "tucked\n",
      "away\n",
      "quiet\n",
      "alley\n",
      "sanctuary\n",
      "chaos\n",
      "warm\n",
      "inviting\n",
      "glow\n",
      "spilling\n",
      "onto\n",
      "cobblestone\n",
      "aroma\n",
      "freshly\n",
      "brewed\n",
      "coffee\n",
      "mingled\n",
      "scent\n",
      "old\n",
      "book\n",
      "lined\n",
      "shelf\n",
      "creating\n",
      "atmosphere\n",
      "comfort\n",
      "nostalgia\n",
      "patron\n",
      "came\n",
      "beverage\n",
      "solace\n",
      "quiet\n",
      "murmur\n",
      "conversation\n",
      "filled\n",
      "air\n",
      "time\n",
      "seemed\n",
      "slow\n",
      "allowing\n",
      "moment\n",
      "linger\n",
      "dream\n",
      "take\n",
      "flight\n",
      "amidst\n",
      "gentle\n",
      "clatter\n",
      "cup\n",
      "soft\n",
      "rustle\n",
      "page\n",
      "turning\n"
     ]
    }
   ],
   "source": [
    "for i in corpus:\n",
    "  words=nltk.word_tokenize(i)# in this step we are reducing the sentences to words\n",
    "  for word in words:\n",
    "    if word not in set(stopwords.words(\"english\")):#in the converted words we are using stopwords\n",
    "      print(lemmatizer.lemmatize(word))#we have applied lemmatizer to the converted words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e7136",
   "metadata": {},
   "source": [
    "# here we are converting the words to vectors with different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cdb128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f08eef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see how NGRAM works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbb8180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(binary=True,ngram_range=(3,3))#we are  using ngram function to convert words to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3c75f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f48fd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in the heart': 43,\n",
       " 'the heart of': 91,\n",
       " 'heart of bustling': 39,\n",
       " 'of bustling city': 55,\n",
       " 'bustling city where': 14,\n",
       " 'city where skyscrapers': 19,\n",
       " 'where skyscrapers reached': 105,\n",
       " 'skyscrapers reached for': 75,\n",
       " 'reached for the': 69,\n",
       " 'for the clouds': 33,\n",
       " 'the clouds and': 88,\n",
       " 'clouds and streets': 21,\n",
       " 'and streets buzzed': 5,\n",
       " 'streets buzzed with': 81,\n",
       " 'buzzed with the': 16,\n",
       " 'with the constant': 107,\n",
       " 'the constant hum': 89,\n",
       " 'constant hum of': 24,\n",
       " 'hum of life': 41,\n",
       " 'of life there': 60,\n",
       " 'life there existed': 48,\n",
       " 'there existed small': 97,\n",
       " 'existed small hidden': 29,\n",
       " 'small hidden caf': 77,\n",
       " 'tucked away in': 102,\n",
       " 'away in quiet': 10,\n",
       " 'in quiet alley': 42,\n",
       " 'quiet alley it': 67,\n",
       " 'alley it was': 0,\n",
       " 'it was sanctuary': 45,\n",
       " 'was sanctuary from': 104,\n",
       " 'sanctuary from the': 71,\n",
       " 'from the chaos': 36,\n",
       " 'the chaos with': 87,\n",
       " 'chaos with its': 18,\n",
       " 'with its warm': 106,\n",
       " 'its warm inviting': 46,\n",
       " 'warm inviting glow': 103,\n",
       " 'inviting glow spilling': 44,\n",
       " 'glow spilling out': 38,\n",
       " 'spilling out onto': 80,\n",
       " 'out onto the': 65,\n",
       " 'onto the cobblestones': 64,\n",
       " 'the aroma of': 85,\n",
       " 'aroma of freshly': 8,\n",
       " 'of freshly brewed': 59,\n",
       " 'freshly brewed coffee': 35,\n",
       " 'brewed coffee mingled': 13,\n",
       " 'coffee mingled with': 22,\n",
       " 'mingled with the': 51,\n",
       " 'with the scent': 108,\n",
       " 'the scent of': 93,\n",
       " 'scent of old': 72,\n",
       " 'of old books': 61,\n",
       " 'old books that': 63,\n",
       " 'books that lined': 12,\n",
       " 'that lined the': 84,\n",
       " 'lined the shelves': 49,\n",
       " 'the shelves creating': 94,\n",
       " 'shelves creating an': 74,\n",
       " 'creating an atmosphere': 26,\n",
       " 'an atmosphere of': 3,\n",
       " 'atmosphere of comfort': 9,\n",
       " 'of comfort and': 56,\n",
       " 'comfort and nostalgia': 23,\n",
       " 'patrons came not': 66,\n",
       " 'came not just': 17,\n",
       " 'not just for': 54,\n",
       " 'just for the': 47,\n",
       " 'for the beverages': 32,\n",
       " 'the beverages but': 86,\n",
       " 'beverages but for': 11,\n",
       " 'but for the': 15,\n",
       " 'for the solace': 34,\n",
       " 'the solace and': 96,\n",
       " 'solace and the': 79,\n",
       " 'and the quiet': 6,\n",
       " 'the quiet murmur': 92,\n",
       " 'quiet murmur of': 68,\n",
       " 'murmur of conversation': 53,\n",
       " 'of conversation that': 57,\n",
       " 'conversation that filled': 25,\n",
       " 'that filled the': 83,\n",
       " 'filled the air': 30,\n",
       " 'here time seemed': 40,\n",
       " 'time seemed to': 98,\n",
       " 'seemed to slow': 73,\n",
       " 'to slow allowing': 100,\n",
       " 'slow allowing moments': 76,\n",
       " 'allowing moments to': 1,\n",
       " 'moments to linger': 52,\n",
       " 'to linger and': 99,\n",
       " 'linger and dreams': 50,\n",
       " 'and dreams to': 4,\n",
       " 'dreams to take': 28,\n",
       " 'to take flight': 101,\n",
       " 'take flight amidst': 82,\n",
       " 'flight amidst the': 31,\n",
       " 'amidst the gentle': 2,\n",
       " 'the gentle clatter': 90,\n",
       " 'gentle clatter of': 37,\n",
       " 'clatter of cups': 20,\n",
       " 'of cups and': 58,\n",
       " 'cups and the': 27,\n",
       " 'and the soft': 7,\n",
       " 'the soft rustle': 95,\n",
       " 'soft rustle of': 78,\n",
       " 'rustle of pages': 70,\n",
       " 'of pages turning': 62}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "345c3c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the heart of a bustling city  where skyscrapers reached for the clouds and streets buzzed with the constant hum of life  there existed a small  hidden caf  '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]#in this we are seeing the 0th position in corpus to just see as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5c492a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].toarray()#in this we are converting the word to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eab9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see how TFIDF works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "157c63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ed86935",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=TfidfVectorizer(ngram_range=(1,1))#ngram can be used only with TFIDF or bag of words it cannot be used alone\n",
    "x=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59c162ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the heart of a bustling city  where skyscrapers reached for the clouds and streets buzzed with the constant hum of life  there existed a small  hidden caf  '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93537188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11908718, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.21137888, 0.        , 0.21137888,\n",
       "        0.21137888, 0.        , 0.        , 0.21137888, 0.        ,\n",
       "        0.21137888, 0.        , 0.        , 0.        , 0.21137888,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21137888,\n",
       "        0.        , 0.        , 0.17053915, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.21137888, 0.        , 0.21137888,\n",
       "        0.21137888, 0.17053915, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.21137888, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23817435,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.21137888, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.21137888, 0.        , 0.21137888,\n",
       "        0.        , 0.        , 0.        , 0.21137888, 0.        ,\n",
       "        0.        , 0.30216951, 0.21137888, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21137888,\n",
       "        0.1415629 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb38001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33b9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7561d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523849a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
